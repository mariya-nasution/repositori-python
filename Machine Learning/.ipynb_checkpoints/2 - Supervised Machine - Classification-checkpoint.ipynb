{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Quantus Telematika Indonesia](../../images/logo-construction-small.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supervised Machine Learning - Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the big three\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# eli5\n",
    "import eli5\n",
    "\n",
    "# scikit-learn\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "# yellowbrick\n",
    "from yellowbrick.classifier import ROCAUC\n",
    "from yellowbrick.classifier import PrecisionRecallCurve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# membaca file csv\n",
    "raw_data = pd.read_csv(\"./dataset/cancer/data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Membaca Metadata**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features are computed from a digitized image of a fine needle aspirate (FNA) of a breast mass. They describe characteristics of the cell nuclei present in the image. n the 3-dimensional space is that described in: [K. P. Bennett and O. L. Mangasarian: \"Robust Linear Programming Discrimination of Two Linearly Inseparable Sets\", Optimization Methods and Software 1, 1992, 23-34].\n",
      "\n",
      "\n",
      "\n",
      "This database is also available through the UW CS ftp server: ftp ftp.cs.wisc.edu cd math-prog/cpo-dataset/machine-learn/WDBC/\n",
      "\n",
      "\n",
      "\n",
      "Also can be found on UCI Machine Learning Repository: https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+%28Diagnostic%29\n",
      "\n",
      "\n",
      "\n",
      "Attribute Information:\n",
      "\n",
      "\n",
      "\n",
      "1) ID number 2) Diagnosis (M = malignant, B = benign) 3-32)\n",
      "\n",
      "\n",
      "\n",
      "Ten real-valued features are computed for each cell nucleus:\n",
      "\n",
      "\n",
      "\n",
      "a) radius (mean of distances from center to points on the perimeter) b) texture (standard deviation of gray-scale values) c) perimeter d) area e) smoothness (local variation in radius lengths) f) compactness (perimeter^2 / area - 1.0) g) concavity (severity of concave portions of the contour) h) concave points (number of concave portions of the contour) i) symmetry j) fractal dimension (\"coastline approximation\" - 1)\n",
      "\n",
      "\n",
      "\n",
      "The mean, standard error and \"worst\" or largest (mean of the three largest values) of these features were computed for each image, resulting in 30 features. For instance, field 3 is Mean Radius, field 13 is Radius SE, field 23 is Worst Radius.\n",
      "\n",
      "\n",
      "\n",
      "All feature values are recoded with four significant digits.\n",
      "\n",
      "\n",
      "\n",
      "Missing attribute values: none\n",
      "\n",
      "\n",
      "\n",
      "Class distribution: 357 benign, 212 malignant\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# membaca metadata\n",
    "with open('./dataset/cancer/data_description.txt', 'r') as f:\n",
    "    teks = f.readlines()\n",
    "    \n",
    "for tulisan in teks:\n",
    "    print(tulisan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>M</td>\n",
       "      <td>17.990</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.300100</td>\n",
       "      <td>0.147100</td>\n",
       "      <td>...</td>\n",
       "      <td>25.380</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.16220</td>\n",
       "      <td>0.66560</td>\n",
       "      <td>0.71190</td>\n",
       "      <td>0.26540</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517</td>\n",
       "      <td>M</td>\n",
       "      <td>20.570</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.086900</td>\n",
       "      <td>0.070170</td>\n",
       "      <td>...</td>\n",
       "      <td>24.990</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.12380</td>\n",
       "      <td>0.18660</td>\n",
       "      <td>0.24160</td>\n",
       "      <td>0.18600</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903</td>\n",
       "      <td>M</td>\n",
       "      <td>19.690</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.197400</td>\n",
       "      <td>0.127900</td>\n",
       "      <td>...</td>\n",
       "      <td>23.570</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.14440</td>\n",
       "      <td>0.42450</td>\n",
       "      <td>0.45040</td>\n",
       "      <td>0.24300</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84348301</td>\n",
       "      <td>M</td>\n",
       "      <td>11.420</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.241400</td>\n",
       "      <td>0.105200</td>\n",
       "      <td>...</td>\n",
       "      <td>14.910</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.20980</td>\n",
       "      <td>0.86630</td>\n",
       "      <td>0.68690</td>\n",
       "      <td>0.25750</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84358402</td>\n",
       "      <td>M</td>\n",
       "      <td>20.290</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.198000</td>\n",
       "      <td>0.104300</td>\n",
       "      <td>...</td>\n",
       "      <td>22.540</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.13740</td>\n",
       "      <td>0.20500</td>\n",
       "      <td>0.40000</td>\n",
       "      <td>0.16250</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>843786</td>\n",
       "      <td>M</td>\n",
       "      <td>12.450</td>\n",
       "      <td>15.70</td>\n",
       "      <td>82.57</td>\n",
       "      <td>477.1</td>\n",
       "      <td>0.12780</td>\n",
       "      <td>0.17000</td>\n",
       "      <td>0.157800</td>\n",
       "      <td>0.080890</td>\n",
       "      <td>...</td>\n",
       "      <td>15.470</td>\n",
       "      <td>23.75</td>\n",
       "      <td>103.40</td>\n",
       "      <td>741.6</td>\n",
       "      <td>0.17910</td>\n",
       "      <td>0.52490</td>\n",
       "      <td>0.53550</td>\n",
       "      <td>0.17410</td>\n",
       "      <td>0.3985</td>\n",
       "      <td>0.12440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>844359</td>\n",
       "      <td>M</td>\n",
       "      <td>18.250</td>\n",
       "      <td>19.98</td>\n",
       "      <td>119.60</td>\n",
       "      <td>1040.0</td>\n",
       "      <td>0.09463</td>\n",
       "      <td>0.10900</td>\n",
       "      <td>0.112700</td>\n",
       "      <td>0.074000</td>\n",
       "      <td>...</td>\n",
       "      <td>22.880</td>\n",
       "      <td>27.66</td>\n",
       "      <td>153.20</td>\n",
       "      <td>1606.0</td>\n",
       "      <td>0.14420</td>\n",
       "      <td>0.25760</td>\n",
       "      <td>0.37840</td>\n",
       "      <td>0.19320</td>\n",
       "      <td>0.3063</td>\n",
       "      <td>0.08368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>84458202</td>\n",
       "      <td>M</td>\n",
       "      <td>13.710</td>\n",
       "      <td>20.83</td>\n",
       "      <td>90.20</td>\n",
       "      <td>577.9</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>0.16450</td>\n",
       "      <td>0.093660</td>\n",
       "      <td>0.059850</td>\n",
       "      <td>...</td>\n",
       "      <td>17.060</td>\n",
       "      <td>28.14</td>\n",
       "      <td>110.60</td>\n",
       "      <td>897.0</td>\n",
       "      <td>0.16540</td>\n",
       "      <td>0.36820</td>\n",
       "      <td>0.26780</td>\n",
       "      <td>0.15560</td>\n",
       "      <td>0.3196</td>\n",
       "      <td>0.11510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>844981</td>\n",
       "      <td>M</td>\n",
       "      <td>13.000</td>\n",
       "      <td>21.82</td>\n",
       "      <td>87.50</td>\n",
       "      <td>519.8</td>\n",
       "      <td>0.12730</td>\n",
       "      <td>0.19320</td>\n",
       "      <td>0.185900</td>\n",
       "      <td>0.093530</td>\n",
       "      <td>...</td>\n",
       "      <td>15.490</td>\n",
       "      <td>30.73</td>\n",
       "      <td>106.20</td>\n",
       "      <td>739.3</td>\n",
       "      <td>0.17030</td>\n",
       "      <td>0.54010</td>\n",
       "      <td>0.53900</td>\n",
       "      <td>0.20600</td>\n",
       "      <td>0.4378</td>\n",
       "      <td>0.10720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>84501001</td>\n",
       "      <td>M</td>\n",
       "      <td>12.460</td>\n",
       "      <td>24.04</td>\n",
       "      <td>83.97</td>\n",
       "      <td>475.9</td>\n",
       "      <td>0.11860</td>\n",
       "      <td>0.23960</td>\n",
       "      <td>0.227300</td>\n",
       "      <td>0.085430</td>\n",
       "      <td>...</td>\n",
       "      <td>15.090</td>\n",
       "      <td>40.68</td>\n",
       "      <td>97.65</td>\n",
       "      <td>711.4</td>\n",
       "      <td>0.18530</td>\n",
       "      <td>1.05800</td>\n",
       "      <td>1.10500</td>\n",
       "      <td>0.22100</td>\n",
       "      <td>0.4366</td>\n",
       "      <td>0.20750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>845636</td>\n",
       "      <td>M</td>\n",
       "      <td>16.020</td>\n",
       "      <td>23.24</td>\n",
       "      <td>102.70</td>\n",
       "      <td>797.8</td>\n",
       "      <td>0.08206</td>\n",
       "      <td>0.06669</td>\n",
       "      <td>0.032990</td>\n",
       "      <td>0.033230</td>\n",
       "      <td>...</td>\n",
       "      <td>19.190</td>\n",
       "      <td>33.88</td>\n",
       "      <td>123.80</td>\n",
       "      <td>1150.0</td>\n",
       "      <td>0.11810</td>\n",
       "      <td>0.15510</td>\n",
       "      <td>0.14590</td>\n",
       "      <td>0.09975</td>\n",
       "      <td>0.2948</td>\n",
       "      <td>0.08452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>84610002</td>\n",
       "      <td>M</td>\n",
       "      <td>15.780</td>\n",
       "      <td>17.89</td>\n",
       "      <td>103.60</td>\n",
       "      <td>781.0</td>\n",
       "      <td>0.09710</td>\n",
       "      <td>0.12920</td>\n",
       "      <td>0.099540</td>\n",
       "      <td>0.066060</td>\n",
       "      <td>...</td>\n",
       "      <td>20.420</td>\n",
       "      <td>27.28</td>\n",
       "      <td>136.50</td>\n",
       "      <td>1299.0</td>\n",
       "      <td>0.13960</td>\n",
       "      <td>0.56090</td>\n",
       "      <td>0.39650</td>\n",
       "      <td>0.18100</td>\n",
       "      <td>0.3792</td>\n",
       "      <td>0.10480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>846226</td>\n",
       "      <td>M</td>\n",
       "      <td>19.170</td>\n",
       "      <td>24.80</td>\n",
       "      <td>132.40</td>\n",
       "      <td>1123.0</td>\n",
       "      <td>0.09740</td>\n",
       "      <td>0.24580</td>\n",
       "      <td>0.206500</td>\n",
       "      <td>0.111800</td>\n",
       "      <td>...</td>\n",
       "      <td>20.960</td>\n",
       "      <td>29.94</td>\n",
       "      <td>151.70</td>\n",
       "      <td>1332.0</td>\n",
       "      <td>0.10370</td>\n",
       "      <td>0.39030</td>\n",
       "      <td>0.36390</td>\n",
       "      <td>0.17670</td>\n",
       "      <td>0.3176</td>\n",
       "      <td>0.10230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>846381</td>\n",
       "      <td>M</td>\n",
       "      <td>15.850</td>\n",
       "      <td>23.95</td>\n",
       "      <td>103.70</td>\n",
       "      <td>782.7</td>\n",
       "      <td>0.08401</td>\n",
       "      <td>0.10020</td>\n",
       "      <td>0.099380</td>\n",
       "      <td>0.053640</td>\n",
       "      <td>...</td>\n",
       "      <td>16.840</td>\n",
       "      <td>27.66</td>\n",
       "      <td>112.00</td>\n",
       "      <td>876.5</td>\n",
       "      <td>0.11310</td>\n",
       "      <td>0.19240</td>\n",
       "      <td>0.23220</td>\n",
       "      <td>0.11190</td>\n",
       "      <td>0.2809</td>\n",
       "      <td>0.06287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>84667401</td>\n",
       "      <td>M</td>\n",
       "      <td>13.730</td>\n",
       "      <td>22.61</td>\n",
       "      <td>93.60</td>\n",
       "      <td>578.3</td>\n",
       "      <td>0.11310</td>\n",
       "      <td>0.22930</td>\n",
       "      <td>0.212800</td>\n",
       "      <td>0.080250</td>\n",
       "      <td>...</td>\n",
       "      <td>15.030</td>\n",
       "      <td>32.01</td>\n",
       "      <td>108.80</td>\n",
       "      <td>697.7</td>\n",
       "      <td>0.16510</td>\n",
       "      <td>0.77250</td>\n",
       "      <td>0.69430</td>\n",
       "      <td>0.22080</td>\n",
       "      <td>0.3596</td>\n",
       "      <td>0.14310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>84799002</td>\n",
       "      <td>M</td>\n",
       "      <td>14.540</td>\n",
       "      <td>27.54</td>\n",
       "      <td>96.73</td>\n",
       "      <td>658.8</td>\n",
       "      <td>0.11390</td>\n",
       "      <td>0.15950</td>\n",
       "      <td>0.163900</td>\n",
       "      <td>0.073640</td>\n",
       "      <td>...</td>\n",
       "      <td>17.460</td>\n",
       "      <td>37.13</td>\n",
       "      <td>124.10</td>\n",
       "      <td>943.2</td>\n",
       "      <td>0.16780</td>\n",
       "      <td>0.65770</td>\n",
       "      <td>0.70260</td>\n",
       "      <td>0.17120</td>\n",
       "      <td>0.4218</td>\n",
       "      <td>0.13410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>848406</td>\n",
       "      <td>M</td>\n",
       "      <td>14.680</td>\n",
       "      <td>20.13</td>\n",
       "      <td>94.74</td>\n",
       "      <td>684.5</td>\n",
       "      <td>0.09867</td>\n",
       "      <td>0.07200</td>\n",
       "      <td>0.073950</td>\n",
       "      <td>0.052590</td>\n",
       "      <td>...</td>\n",
       "      <td>19.070</td>\n",
       "      <td>30.88</td>\n",
       "      <td>123.40</td>\n",
       "      <td>1138.0</td>\n",
       "      <td>0.14640</td>\n",
       "      <td>0.18710</td>\n",
       "      <td>0.29140</td>\n",
       "      <td>0.16090</td>\n",
       "      <td>0.3029</td>\n",
       "      <td>0.08216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>84862001</td>\n",
       "      <td>M</td>\n",
       "      <td>16.130</td>\n",
       "      <td>20.68</td>\n",
       "      <td>108.10</td>\n",
       "      <td>798.8</td>\n",
       "      <td>0.11700</td>\n",
       "      <td>0.20220</td>\n",
       "      <td>0.172200</td>\n",
       "      <td>0.102800</td>\n",
       "      <td>...</td>\n",
       "      <td>20.960</td>\n",
       "      <td>31.48</td>\n",
       "      <td>136.80</td>\n",
       "      <td>1315.0</td>\n",
       "      <td>0.17890</td>\n",
       "      <td>0.42330</td>\n",
       "      <td>0.47840</td>\n",
       "      <td>0.20730</td>\n",
       "      <td>0.3706</td>\n",
       "      <td>0.11420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>849014</td>\n",
       "      <td>M</td>\n",
       "      <td>19.810</td>\n",
       "      <td>22.15</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1260.0</td>\n",
       "      <td>0.09831</td>\n",
       "      <td>0.10270</td>\n",
       "      <td>0.147900</td>\n",
       "      <td>0.094980</td>\n",
       "      <td>...</td>\n",
       "      <td>27.320</td>\n",
       "      <td>30.88</td>\n",
       "      <td>186.80</td>\n",
       "      <td>2398.0</td>\n",
       "      <td>0.15120</td>\n",
       "      <td>0.31500</td>\n",
       "      <td>0.53720</td>\n",
       "      <td>0.23880</td>\n",
       "      <td>0.2768</td>\n",
       "      <td>0.07615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>8510426</td>\n",
       "      <td>B</td>\n",
       "      <td>13.540</td>\n",
       "      <td>14.36</td>\n",
       "      <td>87.46</td>\n",
       "      <td>566.3</td>\n",
       "      <td>0.09779</td>\n",
       "      <td>0.08129</td>\n",
       "      <td>0.066640</td>\n",
       "      <td>0.047810</td>\n",
       "      <td>...</td>\n",
       "      <td>15.110</td>\n",
       "      <td>19.26</td>\n",
       "      <td>99.70</td>\n",
       "      <td>711.2</td>\n",
       "      <td>0.14400</td>\n",
       "      <td>0.17730</td>\n",
       "      <td>0.23900</td>\n",
       "      <td>0.12880</td>\n",
       "      <td>0.2977</td>\n",
       "      <td>0.07259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>8510653</td>\n",
       "      <td>B</td>\n",
       "      <td>13.080</td>\n",
       "      <td>15.71</td>\n",
       "      <td>85.63</td>\n",
       "      <td>520.0</td>\n",
       "      <td>0.10750</td>\n",
       "      <td>0.12700</td>\n",
       "      <td>0.045680</td>\n",
       "      <td>0.031100</td>\n",
       "      <td>...</td>\n",
       "      <td>14.500</td>\n",
       "      <td>20.49</td>\n",
       "      <td>96.09</td>\n",
       "      <td>630.5</td>\n",
       "      <td>0.13120</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.18900</td>\n",
       "      <td>0.07283</td>\n",
       "      <td>0.3184</td>\n",
       "      <td>0.08183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>8510824</td>\n",
       "      <td>B</td>\n",
       "      <td>9.504</td>\n",
       "      <td>12.44</td>\n",
       "      <td>60.34</td>\n",
       "      <td>273.9</td>\n",
       "      <td>0.10240</td>\n",
       "      <td>0.06492</td>\n",
       "      <td>0.029560</td>\n",
       "      <td>0.020760</td>\n",
       "      <td>...</td>\n",
       "      <td>10.230</td>\n",
       "      <td>15.66</td>\n",
       "      <td>65.13</td>\n",
       "      <td>314.9</td>\n",
       "      <td>0.13240</td>\n",
       "      <td>0.11480</td>\n",
       "      <td>0.08867</td>\n",
       "      <td>0.06227</td>\n",
       "      <td>0.2450</td>\n",
       "      <td>0.07773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>8511133</td>\n",
       "      <td>M</td>\n",
       "      <td>15.340</td>\n",
       "      <td>14.26</td>\n",
       "      <td>102.50</td>\n",
       "      <td>704.4</td>\n",
       "      <td>0.10730</td>\n",
       "      <td>0.21350</td>\n",
       "      <td>0.207700</td>\n",
       "      <td>0.097560</td>\n",
       "      <td>...</td>\n",
       "      <td>18.070</td>\n",
       "      <td>19.08</td>\n",
       "      <td>125.10</td>\n",
       "      <td>980.9</td>\n",
       "      <td>0.13900</td>\n",
       "      <td>0.59540</td>\n",
       "      <td>0.63050</td>\n",
       "      <td>0.23930</td>\n",
       "      <td>0.4667</td>\n",
       "      <td>0.09946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>851509</td>\n",
       "      <td>M</td>\n",
       "      <td>21.160</td>\n",
       "      <td>23.04</td>\n",
       "      <td>137.20</td>\n",
       "      <td>1404.0</td>\n",
       "      <td>0.09428</td>\n",
       "      <td>0.10220</td>\n",
       "      <td>0.109700</td>\n",
       "      <td>0.086320</td>\n",
       "      <td>...</td>\n",
       "      <td>29.170</td>\n",
       "      <td>35.59</td>\n",
       "      <td>188.00</td>\n",
       "      <td>2615.0</td>\n",
       "      <td>0.14010</td>\n",
       "      <td>0.26000</td>\n",
       "      <td>0.31550</td>\n",
       "      <td>0.20090</td>\n",
       "      <td>0.2822</td>\n",
       "      <td>0.07526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>852552</td>\n",
       "      <td>M</td>\n",
       "      <td>16.650</td>\n",
       "      <td>21.38</td>\n",
       "      <td>110.00</td>\n",
       "      <td>904.6</td>\n",
       "      <td>0.11210</td>\n",
       "      <td>0.14570</td>\n",
       "      <td>0.152500</td>\n",
       "      <td>0.091700</td>\n",
       "      <td>...</td>\n",
       "      <td>26.460</td>\n",
       "      <td>31.56</td>\n",
       "      <td>177.00</td>\n",
       "      <td>2215.0</td>\n",
       "      <td>0.18050</td>\n",
       "      <td>0.35780</td>\n",
       "      <td>0.46950</td>\n",
       "      <td>0.20950</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.09564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>852631</td>\n",
       "      <td>M</td>\n",
       "      <td>17.140</td>\n",
       "      <td>16.40</td>\n",
       "      <td>116.00</td>\n",
       "      <td>912.7</td>\n",
       "      <td>0.11860</td>\n",
       "      <td>0.22760</td>\n",
       "      <td>0.222900</td>\n",
       "      <td>0.140100</td>\n",
       "      <td>...</td>\n",
       "      <td>22.250</td>\n",
       "      <td>21.40</td>\n",
       "      <td>152.40</td>\n",
       "      <td>1461.0</td>\n",
       "      <td>0.15450</td>\n",
       "      <td>0.39490</td>\n",
       "      <td>0.38530</td>\n",
       "      <td>0.25500</td>\n",
       "      <td>0.4066</td>\n",
       "      <td>0.10590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>852763</td>\n",
       "      <td>M</td>\n",
       "      <td>14.580</td>\n",
       "      <td>21.53</td>\n",
       "      <td>97.41</td>\n",
       "      <td>644.8</td>\n",
       "      <td>0.10540</td>\n",
       "      <td>0.18680</td>\n",
       "      <td>0.142500</td>\n",
       "      <td>0.087830</td>\n",
       "      <td>...</td>\n",
       "      <td>17.620</td>\n",
       "      <td>33.21</td>\n",
       "      <td>122.40</td>\n",
       "      <td>896.9</td>\n",
       "      <td>0.15250</td>\n",
       "      <td>0.66430</td>\n",
       "      <td>0.55390</td>\n",
       "      <td>0.27010</td>\n",
       "      <td>0.4264</td>\n",
       "      <td>0.12750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>852781</td>\n",
       "      <td>M</td>\n",
       "      <td>18.610</td>\n",
       "      <td>20.25</td>\n",
       "      <td>122.10</td>\n",
       "      <td>1094.0</td>\n",
       "      <td>0.09440</td>\n",
       "      <td>0.10660</td>\n",
       "      <td>0.149000</td>\n",
       "      <td>0.077310</td>\n",
       "      <td>...</td>\n",
       "      <td>21.310</td>\n",
       "      <td>27.26</td>\n",
       "      <td>139.90</td>\n",
       "      <td>1403.0</td>\n",
       "      <td>0.13380</td>\n",
       "      <td>0.21170</td>\n",
       "      <td>0.34460</td>\n",
       "      <td>0.14900</td>\n",
       "      <td>0.2341</td>\n",
       "      <td>0.07421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>852973</td>\n",
       "      <td>M</td>\n",
       "      <td>15.300</td>\n",
       "      <td>25.27</td>\n",
       "      <td>102.40</td>\n",
       "      <td>732.4</td>\n",
       "      <td>0.10820</td>\n",
       "      <td>0.16970</td>\n",
       "      <td>0.168300</td>\n",
       "      <td>0.087510</td>\n",
       "      <td>...</td>\n",
       "      <td>20.270</td>\n",
       "      <td>36.71</td>\n",
       "      <td>149.30</td>\n",
       "      <td>1269.0</td>\n",
       "      <td>0.16410</td>\n",
       "      <td>0.61100</td>\n",
       "      <td>0.63350</td>\n",
       "      <td>0.20240</td>\n",
       "      <td>0.4027</td>\n",
       "      <td>0.09876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>853201</td>\n",
       "      <td>M</td>\n",
       "      <td>17.570</td>\n",
       "      <td>15.05</td>\n",
       "      <td>115.00</td>\n",
       "      <td>955.1</td>\n",
       "      <td>0.09847</td>\n",
       "      <td>0.11570</td>\n",
       "      <td>0.098750</td>\n",
       "      <td>0.079530</td>\n",
       "      <td>...</td>\n",
       "      <td>20.010</td>\n",
       "      <td>19.52</td>\n",
       "      <td>134.90</td>\n",
       "      <td>1227.0</td>\n",
       "      <td>0.12550</td>\n",
       "      <td>0.28120</td>\n",
       "      <td>0.24890</td>\n",
       "      <td>0.14560</td>\n",
       "      <td>0.2756</td>\n",
       "      <td>0.07919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>539</th>\n",
       "      <td>921362</td>\n",
       "      <td>B</td>\n",
       "      <td>7.691</td>\n",
       "      <td>25.44</td>\n",
       "      <td>48.34</td>\n",
       "      <td>170.4</td>\n",
       "      <td>0.08668</td>\n",
       "      <td>0.11990</td>\n",
       "      <td>0.092520</td>\n",
       "      <td>0.013640</td>\n",
       "      <td>...</td>\n",
       "      <td>8.678</td>\n",
       "      <td>31.89</td>\n",
       "      <td>54.49</td>\n",
       "      <td>223.6</td>\n",
       "      <td>0.15960</td>\n",
       "      <td>0.30640</td>\n",
       "      <td>0.33930</td>\n",
       "      <td>0.05000</td>\n",
       "      <td>0.2790</td>\n",
       "      <td>0.10660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>540</th>\n",
       "      <td>921385</td>\n",
       "      <td>B</td>\n",
       "      <td>11.540</td>\n",
       "      <td>14.44</td>\n",
       "      <td>74.65</td>\n",
       "      <td>402.9</td>\n",
       "      <td>0.09984</td>\n",
       "      <td>0.11200</td>\n",
       "      <td>0.067370</td>\n",
       "      <td>0.025940</td>\n",
       "      <td>...</td>\n",
       "      <td>12.260</td>\n",
       "      <td>19.68</td>\n",
       "      <td>78.78</td>\n",
       "      <td>457.8</td>\n",
       "      <td>0.13450</td>\n",
       "      <td>0.21180</td>\n",
       "      <td>0.17970</td>\n",
       "      <td>0.06918</td>\n",
       "      <td>0.2329</td>\n",
       "      <td>0.08134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>541</th>\n",
       "      <td>921386</td>\n",
       "      <td>B</td>\n",
       "      <td>14.470</td>\n",
       "      <td>24.99</td>\n",
       "      <td>95.81</td>\n",
       "      <td>656.4</td>\n",
       "      <td>0.08837</td>\n",
       "      <td>0.12300</td>\n",
       "      <td>0.100900</td>\n",
       "      <td>0.038900</td>\n",
       "      <td>...</td>\n",
       "      <td>16.220</td>\n",
       "      <td>31.73</td>\n",
       "      <td>113.50</td>\n",
       "      <td>808.9</td>\n",
       "      <td>0.13400</td>\n",
       "      <td>0.42020</td>\n",
       "      <td>0.40400</td>\n",
       "      <td>0.12050</td>\n",
       "      <td>0.3187</td>\n",
       "      <td>0.10230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>542</th>\n",
       "      <td>921644</td>\n",
       "      <td>B</td>\n",
       "      <td>14.740</td>\n",
       "      <td>25.42</td>\n",
       "      <td>94.70</td>\n",
       "      <td>668.6</td>\n",
       "      <td>0.08275</td>\n",
       "      <td>0.07214</td>\n",
       "      <td>0.041050</td>\n",
       "      <td>0.030270</td>\n",
       "      <td>...</td>\n",
       "      <td>16.510</td>\n",
       "      <td>32.29</td>\n",
       "      <td>107.40</td>\n",
       "      <td>826.4</td>\n",
       "      <td>0.10600</td>\n",
       "      <td>0.13760</td>\n",
       "      <td>0.16110</td>\n",
       "      <td>0.10950</td>\n",
       "      <td>0.2722</td>\n",
       "      <td>0.06956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>543</th>\n",
       "      <td>922296</td>\n",
       "      <td>B</td>\n",
       "      <td>13.210</td>\n",
       "      <td>28.06</td>\n",
       "      <td>84.88</td>\n",
       "      <td>538.4</td>\n",
       "      <td>0.08671</td>\n",
       "      <td>0.06877</td>\n",
       "      <td>0.029870</td>\n",
       "      <td>0.032750</td>\n",
       "      <td>...</td>\n",
       "      <td>14.370</td>\n",
       "      <td>37.17</td>\n",
       "      <td>92.48</td>\n",
       "      <td>629.6</td>\n",
       "      <td>0.10720</td>\n",
       "      <td>0.13810</td>\n",
       "      <td>0.10620</td>\n",
       "      <td>0.07958</td>\n",
       "      <td>0.2473</td>\n",
       "      <td>0.06443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>544</th>\n",
       "      <td>922297</td>\n",
       "      <td>B</td>\n",
       "      <td>13.870</td>\n",
       "      <td>20.70</td>\n",
       "      <td>89.77</td>\n",
       "      <td>584.8</td>\n",
       "      <td>0.09578</td>\n",
       "      <td>0.10180</td>\n",
       "      <td>0.036880</td>\n",
       "      <td>0.023690</td>\n",
       "      <td>...</td>\n",
       "      <td>15.050</td>\n",
       "      <td>24.75</td>\n",
       "      <td>99.17</td>\n",
       "      <td>688.6</td>\n",
       "      <td>0.12640</td>\n",
       "      <td>0.20370</td>\n",
       "      <td>0.13770</td>\n",
       "      <td>0.06845</td>\n",
       "      <td>0.2249</td>\n",
       "      <td>0.08492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>545</th>\n",
       "      <td>922576</td>\n",
       "      <td>B</td>\n",
       "      <td>13.620</td>\n",
       "      <td>23.23</td>\n",
       "      <td>87.19</td>\n",
       "      <td>573.2</td>\n",
       "      <td>0.09246</td>\n",
       "      <td>0.06747</td>\n",
       "      <td>0.029740</td>\n",
       "      <td>0.024430</td>\n",
       "      <td>...</td>\n",
       "      <td>15.350</td>\n",
       "      <td>29.09</td>\n",
       "      <td>97.58</td>\n",
       "      <td>729.8</td>\n",
       "      <td>0.12160</td>\n",
       "      <td>0.15170</td>\n",
       "      <td>0.10490</td>\n",
       "      <td>0.07174</td>\n",
       "      <td>0.2642</td>\n",
       "      <td>0.06953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>546</th>\n",
       "      <td>922577</td>\n",
       "      <td>B</td>\n",
       "      <td>10.320</td>\n",
       "      <td>16.35</td>\n",
       "      <td>65.31</td>\n",
       "      <td>324.9</td>\n",
       "      <td>0.09434</td>\n",
       "      <td>0.04994</td>\n",
       "      <td>0.010120</td>\n",
       "      <td>0.005495</td>\n",
       "      <td>...</td>\n",
       "      <td>11.250</td>\n",
       "      <td>21.77</td>\n",
       "      <td>71.12</td>\n",
       "      <td>384.9</td>\n",
       "      <td>0.12850</td>\n",
       "      <td>0.08842</td>\n",
       "      <td>0.04384</td>\n",
       "      <td>0.02381</td>\n",
       "      <td>0.2681</td>\n",
       "      <td>0.07399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>547</th>\n",
       "      <td>922840</td>\n",
       "      <td>B</td>\n",
       "      <td>10.260</td>\n",
       "      <td>16.58</td>\n",
       "      <td>65.85</td>\n",
       "      <td>320.8</td>\n",
       "      <td>0.08877</td>\n",
       "      <td>0.08066</td>\n",
       "      <td>0.043580</td>\n",
       "      <td>0.024380</td>\n",
       "      <td>...</td>\n",
       "      <td>10.830</td>\n",
       "      <td>22.04</td>\n",
       "      <td>71.08</td>\n",
       "      <td>357.4</td>\n",
       "      <td>0.14610</td>\n",
       "      <td>0.22460</td>\n",
       "      <td>0.17830</td>\n",
       "      <td>0.08333</td>\n",
       "      <td>0.2691</td>\n",
       "      <td>0.09479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>548</th>\n",
       "      <td>923169</td>\n",
       "      <td>B</td>\n",
       "      <td>9.683</td>\n",
       "      <td>19.34</td>\n",
       "      <td>61.05</td>\n",
       "      <td>285.7</td>\n",
       "      <td>0.08491</td>\n",
       "      <td>0.05030</td>\n",
       "      <td>0.023370</td>\n",
       "      <td>0.009615</td>\n",
       "      <td>...</td>\n",
       "      <td>10.930</td>\n",
       "      <td>25.59</td>\n",
       "      <td>69.10</td>\n",
       "      <td>364.2</td>\n",
       "      <td>0.11990</td>\n",
       "      <td>0.09546</td>\n",
       "      <td>0.09350</td>\n",
       "      <td>0.03846</td>\n",
       "      <td>0.2552</td>\n",
       "      <td>0.07920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>549</th>\n",
       "      <td>923465</td>\n",
       "      <td>B</td>\n",
       "      <td>10.820</td>\n",
       "      <td>24.21</td>\n",
       "      <td>68.89</td>\n",
       "      <td>361.6</td>\n",
       "      <td>0.08192</td>\n",
       "      <td>0.06602</td>\n",
       "      <td>0.015480</td>\n",
       "      <td>0.008160</td>\n",
       "      <td>...</td>\n",
       "      <td>13.030</td>\n",
       "      <td>31.45</td>\n",
       "      <td>83.90</td>\n",
       "      <td>505.6</td>\n",
       "      <td>0.12040</td>\n",
       "      <td>0.16330</td>\n",
       "      <td>0.06194</td>\n",
       "      <td>0.03264</td>\n",
       "      <td>0.3059</td>\n",
       "      <td>0.07626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>550</th>\n",
       "      <td>923748</td>\n",
       "      <td>B</td>\n",
       "      <td>10.860</td>\n",
       "      <td>21.48</td>\n",
       "      <td>68.51</td>\n",
       "      <td>360.5</td>\n",
       "      <td>0.07431</td>\n",
       "      <td>0.04227</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>11.660</td>\n",
       "      <td>24.77</td>\n",
       "      <td>74.08</td>\n",
       "      <td>412.3</td>\n",
       "      <td>0.10010</td>\n",
       "      <td>0.07348</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.2458</td>\n",
       "      <td>0.06592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>551</th>\n",
       "      <td>923780</td>\n",
       "      <td>B</td>\n",
       "      <td>11.130</td>\n",
       "      <td>22.44</td>\n",
       "      <td>71.49</td>\n",
       "      <td>378.4</td>\n",
       "      <td>0.09566</td>\n",
       "      <td>0.08194</td>\n",
       "      <td>0.048240</td>\n",
       "      <td>0.022570</td>\n",
       "      <td>...</td>\n",
       "      <td>12.020</td>\n",
       "      <td>28.26</td>\n",
       "      <td>77.80</td>\n",
       "      <td>436.6</td>\n",
       "      <td>0.10870</td>\n",
       "      <td>0.17820</td>\n",
       "      <td>0.15640</td>\n",
       "      <td>0.06413</td>\n",
       "      <td>0.3169</td>\n",
       "      <td>0.08032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>552</th>\n",
       "      <td>924084</td>\n",
       "      <td>B</td>\n",
       "      <td>12.770</td>\n",
       "      <td>29.43</td>\n",
       "      <td>81.35</td>\n",
       "      <td>507.9</td>\n",
       "      <td>0.08276</td>\n",
       "      <td>0.04234</td>\n",
       "      <td>0.019970</td>\n",
       "      <td>0.014990</td>\n",
       "      <td>...</td>\n",
       "      <td>13.870</td>\n",
       "      <td>36.00</td>\n",
       "      <td>88.10</td>\n",
       "      <td>594.7</td>\n",
       "      <td>0.12340</td>\n",
       "      <td>0.10640</td>\n",
       "      <td>0.08653</td>\n",
       "      <td>0.06498</td>\n",
       "      <td>0.2407</td>\n",
       "      <td>0.06484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>553</th>\n",
       "      <td>924342</td>\n",
       "      <td>B</td>\n",
       "      <td>9.333</td>\n",
       "      <td>21.94</td>\n",
       "      <td>59.01</td>\n",
       "      <td>264.0</td>\n",
       "      <td>0.09240</td>\n",
       "      <td>0.05605</td>\n",
       "      <td>0.039960</td>\n",
       "      <td>0.012820</td>\n",
       "      <td>...</td>\n",
       "      <td>9.845</td>\n",
       "      <td>25.05</td>\n",
       "      <td>62.86</td>\n",
       "      <td>295.8</td>\n",
       "      <td>0.11030</td>\n",
       "      <td>0.08298</td>\n",
       "      <td>0.07993</td>\n",
       "      <td>0.02564</td>\n",
       "      <td>0.2435</td>\n",
       "      <td>0.07393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>554</th>\n",
       "      <td>924632</td>\n",
       "      <td>B</td>\n",
       "      <td>12.880</td>\n",
       "      <td>28.92</td>\n",
       "      <td>82.50</td>\n",
       "      <td>514.3</td>\n",
       "      <td>0.08123</td>\n",
       "      <td>0.05824</td>\n",
       "      <td>0.061950</td>\n",
       "      <td>0.023430</td>\n",
       "      <td>...</td>\n",
       "      <td>13.890</td>\n",
       "      <td>35.74</td>\n",
       "      <td>88.84</td>\n",
       "      <td>595.7</td>\n",
       "      <td>0.12270</td>\n",
       "      <td>0.16200</td>\n",
       "      <td>0.24390</td>\n",
       "      <td>0.06493</td>\n",
       "      <td>0.2372</td>\n",
       "      <td>0.07242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>555</th>\n",
       "      <td>924934</td>\n",
       "      <td>B</td>\n",
       "      <td>10.290</td>\n",
       "      <td>27.61</td>\n",
       "      <td>65.67</td>\n",
       "      <td>321.4</td>\n",
       "      <td>0.09030</td>\n",
       "      <td>0.07658</td>\n",
       "      <td>0.059990</td>\n",
       "      <td>0.027380</td>\n",
       "      <td>...</td>\n",
       "      <td>10.840</td>\n",
       "      <td>34.91</td>\n",
       "      <td>69.57</td>\n",
       "      <td>357.6</td>\n",
       "      <td>0.13840</td>\n",
       "      <td>0.17100</td>\n",
       "      <td>0.20000</td>\n",
       "      <td>0.09127</td>\n",
       "      <td>0.2226</td>\n",
       "      <td>0.08283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>556</th>\n",
       "      <td>924964</td>\n",
       "      <td>B</td>\n",
       "      <td>10.160</td>\n",
       "      <td>19.59</td>\n",
       "      <td>64.73</td>\n",
       "      <td>311.7</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.07504</td>\n",
       "      <td>0.005025</td>\n",
       "      <td>0.011160</td>\n",
       "      <td>...</td>\n",
       "      <td>10.650</td>\n",
       "      <td>22.88</td>\n",
       "      <td>67.88</td>\n",
       "      <td>347.3</td>\n",
       "      <td>0.12650</td>\n",
       "      <td>0.12000</td>\n",
       "      <td>0.01005</td>\n",
       "      <td>0.02232</td>\n",
       "      <td>0.2262</td>\n",
       "      <td>0.06742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>557</th>\n",
       "      <td>925236</td>\n",
       "      <td>B</td>\n",
       "      <td>9.423</td>\n",
       "      <td>27.88</td>\n",
       "      <td>59.26</td>\n",
       "      <td>271.3</td>\n",
       "      <td>0.08123</td>\n",
       "      <td>0.04971</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>10.490</td>\n",
       "      <td>34.24</td>\n",
       "      <td>66.50</td>\n",
       "      <td>330.6</td>\n",
       "      <td>0.10730</td>\n",
       "      <td>0.07158</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.2475</td>\n",
       "      <td>0.06969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>558</th>\n",
       "      <td>925277</td>\n",
       "      <td>B</td>\n",
       "      <td>14.590</td>\n",
       "      <td>22.68</td>\n",
       "      <td>96.39</td>\n",
       "      <td>657.1</td>\n",
       "      <td>0.08473</td>\n",
       "      <td>0.13300</td>\n",
       "      <td>0.102900</td>\n",
       "      <td>0.037360</td>\n",
       "      <td>...</td>\n",
       "      <td>15.480</td>\n",
       "      <td>27.27</td>\n",
       "      <td>105.90</td>\n",
       "      <td>733.5</td>\n",
       "      <td>0.10260</td>\n",
       "      <td>0.31710</td>\n",
       "      <td>0.36620</td>\n",
       "      <td>0.11050</td>\n",
       "      <td>0.2258</td>\n",
       "      <td>0.08004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>559</th>\n",
       "      <td>925291</td>\n",
       "      <td>B</td>\n",
       "      <td>11.510</td>\n",
       "      <td>23.93</td>\n",
       "      <td>74.52</td>\n",
       "      <td>403.5</td>\n",
       "      <td>0.09261</td>\n",
       "      <td>0.10210</td>\n",
       "      <td>0.111200</td>\n",
       "      <td>0.041050</td>\n",
       "      <td>...</td>\n",
       "      <td>12.480</td>\n",
       "      <td>37.16</td>\n",
       "      <td>82.28</td>\n",
       "      <td>474.2</td>\n",
       "      <td>0.12980</td>\n",
       "      <td>0.25170</td>\n",
       "      <td>0.36300</td>\n",
       "      <td>0.09653</td>\n",
       "      <td>0.2112</td>\n",
       "      <td>0.08732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>560</th>\n",
       "      <td>925292</td>\n",
       "      <td>B</td>\n",
       "      <td>14.050</td>\n",
       "      <td>27.15</td>\n",
       "      <td>91.38</td>\n",
       "      <td>600.4</td>\n",
       "      <td>0.09929</td>\n",
       "      <td>0.11260</td>\n",
       "      <td>0.044620</td>\n",
       "      <td>0.043040</td>\n",
       "      <td>...</td>\n",
       "      <td>15.300</td>\n",
       "      <td>33.17</td>\n",
       "      <td>100.20</td>\n",
       "      <td>706.7</td>\n",
       "      <td>0.12410</td>\n",
       "      <td>0.22640</td>\n",
       "      <td>0.13260</td>\n",
       "      <td>0.10480</td>\n",
       "      <td>0.2250</td>\n",
       "      <td>0.08321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>561</th>\n",
       "      <td>925311</td>\n",
       "      <td>B</td>\n",
       "      <td>11.200</td>\n",
       "      <td>29.37</td>\n",
       "      <td>70.67</td>\n",
       "      <td>386.0</td>\n",
       "      <td>0.07449</td>\n",
       "      <td>0.03558</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>11.920</td>\n",
       "      <td>38.30</td>\n",
       "      <td>75.19</td>\n",
       "      <td>439.6</td>\n",
       "      <td>0.09267</td>\n",
       "      <td>0.05494</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.1566</td>\n",
       "      <td>0.05905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>562</th>\n",
       "      <td>925622</td>\n",
       "      <td>M</td>\n",
       "      <td>15.220</td>\n",
       "      <td>30.62</td>\n",
       "      <td>103.40</td>\n",
       "      <td>716.9</td>\n",
       "      <td>0.10480</td>\n",
       "      <td>0.20870</td>\n",
       "      <td>0.255000</td>\n",
       "      <td>0.094290</td>\n",
       "      <td>...</td>\n",
       "      <td>17.520</td>\n",
       "      <td>42.79</td>\n",
       "      <td>128.70</td>\n",
       "      <td>915.0</td>\n",
       "      <td>0.14170</td>\n",
       "      <td>0.79170</td>\n",
       "      <td>1.17000</td>\n",
       "      <td>0.23560</td>\n",
       "      <td>0.4089</td>\n",
       "      <td>0.14090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>563</th>\n",
       "      <td>926125</td>\n",
       "      <td>M</td>\n",
       "      <td>20.920</td>\n",
       "      <td>25.09</td>\n",
       "      <td>143.00</td>\n",
       "      <td>1347.0</td>\n",
       "      <td>0.10990</td>\n",
       "      <td>0.22360</td>\n",
       "      <td>0.317400</td>\n",
       "      <td>0.147400</td>\n",
       "      <td>...</td>\n",
       "      <td>24.290</td>\n",
       "      <td>29.41</td>\n",
       "      <td>179.10</td>\n",
       "      <td>1819.0</td>\n",
       "      <td>0.14070</td>\n",
       "      <td>0.41860</td>\n",
       "      <td>0.65990</td>\n",
       "      <td>0.25420</td>\n",
       "      <td>0.2929</td>\n",
       "      <td>0.09873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>926424</td>\n",
       "      <td>M</td>\n",
       "      <td>21.560</td>\n",
       "      <td>22.39</td>\n",
       "      <td>142.00</td>\n",
       "      <td>1479.0</td>\n",
       "      <td>0.11100</td>\n",
       "      <td>0.11590</td>\n",
       "      <td>0.243900</td>\n",
       "      <td>0.138900</td>\n",
       "      <td>...</td>\n",
       "      <td>25.450</td>\n",
       "      <td>26.40</td>\n",
       "      <td>166.10</td>\n",
       "      <td>2027.0</td>\n",
       "      <td>0.14100</td>\n",
       "      <td>0.21130</td>\n",
       "      <td>0.41070</td>\n",
       "      <td>0.22160</td>\n",
       "      <td>0.2060</td>\n",
       "      <td>0.07115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>926682</td>\n",
       "      <td>M</td>\n",
       "      <td>20.130</td>\n",
       "      <td>28.25</td>\n",
       "      <td>131.20</td>\n",
       "      <td>1261.0</td>\n",
       "      <td>0.09780</td>\n",
       "      <td>0.10340</td>\n",
       "      <td>0.144000</td>\n",
       "      <td>0.097910</td>\n",
       "      <td>...</td>\n",
       "      <td>23.690</td>\n",
       "      <td>38.25</td>\n",
       "      <td>155.00</td>\n",
       "      <td>1731.0</td>\n",
       "      <td>0.11660</td>\n",
       "      <td>0.19220</td>\n",
       "      <td>0.32150</td>\n",
       "      <td>0.16280</td>\n",
       "      <td>0.2572</td>\n",
       "      <td>0.06637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>926954</td>\n",
       "      <td>M</td>\n",
       "      <td>16.600</td>\n",
       "      <td>28.08</td>\n",
       "      <td>108.30</td>\n",
       "      <td>858.1</td>\n",
       "      <td>0.08455</td>\n",
       "      <td>0.10230</td>\n",
       "      <td>0.092510</td>\n",
       "      <td>0.053020</td>\n",
       "      <td>...</td>\n",
       "      <td>18.980</td>\n",
       "      <td>34.12</td>\n",
       "      <td>126.70</td>\n",
       "      <td>1124.0</td>\n",
       "      <td>0.11390</td>\n",
       "      <td>0.30940</td>\n",
       "      <td>0.34030</td>\n",
       "      <td>0.14180</td>\n",
       "      <td>0.2218</td>\n",
       "      <td>0.07820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>927241</td>\n",
       "      <td>M</td>\n",
       "      <td>20.600</td>\n",
       "      <td>29.33</td>\n",
       "      <td>140.10</td>\n",
       "      <td>1265.0</td>\n",
       "      <td>0.11780</td>\n",
       "      <td>0.27700</td>\n",
       "      <td>0.351400</td>\n",
       "      <td>0.152000</td>\n",
       "      <td>...</td>\n",
       "      <td>25.740</td>\n",
       "      <td>39.42</td>\n",
       "      <td>184.60</td>\n",
       "      <td>1821.0</td>\n",
       "      <td>0.16500</td>\n",
       "      <td>0.86810</td>\n",
       "      <td>0.93870</td>\n",
       "      <td>0.26500</td>\n",
       "      <td>0.4087</td>\n",
       "      <td>0.12400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>92751</td>\n",
       "      <td>B</td>\n",
       "      <td>7.760</td>\n",
       "      <td>24.54</td>\n",
       "      <td>47.92</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.05263</td>\n",
       "      <td>0.04362</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>9.456</td>\n",
       "      <td>30.37</td>\n",
       "      <td>59.16</td>\n",
       "      <td>268.6</td>\n",
       "      <td>0.08996</td>\n",
       "      <td>0.06444</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.2871</td>\n",
       "      <td>0.07039</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows  32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0      842302         M       17.990         10.38          122.80     1001.0   \n",
       "1      842517         M       20.570         17.77          132.90     1326.0   \n",
       "2    84300903         M       19.690         21.25          130.00     1203.0   \n",
       "3    84348301         M       11.420         20.38           77.58      386.1   \n",
       "4    84358402         M       20.290         14.34          135.10     1297.0   \n",
       "5      843786         M       12.450         15.70           82.57      477.1   \n",
       "6      844359         M       18.250         19.98          119.60     1040.0   \n",
       "7    84458202         M       13.710         20.83           90.20      577.9   \n",
       "8      844981         M       13.000         21.82           87.50      519.8   \n",
       "9    84501001         M       12.460         24.04           83.97      475.9   \n",
       "10     845636         M       16.020         23.24          102.70      797.8   \n",
       "11   84610002         M       15.780         17.89          103.60      781.0   \n",
       "12     846226         M       19.170         24.80          132.40     1123.0   \n",
       "13     846381         M       15.850         23.95          103.70      782.7   \n",
       "14   84667401         M       13.730         22.61           93.60      578.3   \n",
       "15   84799002         M       14.540         27.54           96.73      658.8   \n",
       "16     848406         M       14.680         20.13           94.74      684.5   \n",
       "17   84862001         M       16.130         20.68          108.10      798.8   \n",
       "18     849014         M       19.810         22.15          130.00     1260.0   \n",
       "19    8510426         B       13.540         14.36           87.46      566.3   \n",
       "20    8510653         B       13.080         15.71           85.63      520.0   \n",
       "21    8510824         B        9.504         12.44           60.34      273.9   \n",
       "22    8511133         M       15.340         14.26          102.50      704.4   \n",
       "23     851509         M       21.160         23.04          137.20     1404.0   \n",
       "24     852552         M       16.650         21.38          110.00      904.6   \n",
       "25     852631         M       17.140         16.40          116.00      912.7   \n",
       "26     852763         M       14.580         21.53           97.41      644.8   \n",
       "27     852781         M       18.610         20.25          122.10     1094.0   \n",
       "28     852973         M       15.300         25.27          102.40      732.4   \n",
       "29     853201         M       17.570         15.05          115.00      955.1   \n",
       "..        ...       ...          ...           ...             ...        ...   \n",
       "539    921362         B        7.691         25.44           48.34      170.4   \n",
       "540    921385         B       11.540         14.44           74.65      402.9   \n",
       "541    921386         B       14.470         24.99           95.81      656.4   \n",
       "542    921644         B       14.740         25.42           94.70      668.6   \n",
       "543    922296         B       13.210         28.06           84.88      538.4   \n",
       "544    922297         B       13.870         20.70           89.77      584.8   \n",
       "545    922576         B       13.620         23.23           87.19      573.2   \n",
       "546    922577         B       10.320         16.35           65.31      324.9   \n",
       "547    922840         B       10.260         16.58           65.85      320.8   \n",
       "548    923169         B        9.683         19.34           61.05      285.7   \n",
       "549    923465         B       10.820         24.21           68.89      361.6   \n",
       "550    923748         B       10.860         21.48           68.51      360.5   \n",
       "551    923780         B       11.130         22.44           71.49      378.4   \n",
       "552    924084         B       12.770         29.43           81.35      507.9   \n",
       "553    924342         B        9.333         21.94           59.01      264.0   \n",
       "554    924632         B       12.880         28.92           82.50      514.3   \n",
       "555    924934         B       10.290         27.61           65.67      321.4   \n",
       "556    924964         B       10.160         19.59           64.73      311.7   \n",
       "557    925236         B        9.423         27.88           59.26      271.3   \n",
       "558    925277         B       14.590         22.68           96.39      657.1   \n",
       "559    925291         B       11.510         23.93           74.52      403.5   \n",
       "560    925292         B       14.050         27.15           91.38      600.4   \n",
       "561    925311         B       11.200         29.37           70.67      386.0   \n",
       "562    925622         M       15.220         30.62          103.40      716.9   \n",
       "563    926125         M       20.920         25.09          143.00     1347.0   \n",
       "564    926424         M       21.560         22.39          142.00     1479.0   \n",
       "565    926682         M       20.130         28.25          131.20     1261.0   \n",
       "566    926954         M       16.600         28.08          108.30      858.1   \n",
       "567    927241         M       20.600         29.33          140.10     1265.0   \n",
       "568     92751         B        7.760         24.54           47.92      181.0   \n",
       "\n",
       "     smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0            0.11840           0.27760        0.300100             0.147100   \n",
       "1            0.08474           0.07864        0.086900             0.070170   \n",
       "2            0.10960           0.15990        0.197400             0.127900   \n",
       "3            0.14250           0.28390        0.241400             0.105200   \n",
       "4            0.10030           0.13280        0.198000             0.104300   \n",
       "5            0.12780           0.17000        0.157800             0.080890   \n",
       "6            0.09463           0.10900        0.112700             0.074000   \n",
       "7            0.11890           0.16450        0.093660             0.059850   \n",
       "8            0.12730           0.19320        0.185900             0.093530   \n",
       "9            0.11860           0.23960        0.227300             0.085430   \n",
       "10           0.08206           0.06669        0.032990             0.033230   \n",
       "11           0.09710           0.12920        0.099540             0.066060   \n",
       "12           0.09740           0.24580        0.206500             0.111800   \n",
       "13           0.08401           0.10020        0.099380             0.053640   \n",
       "14           0.11310           0.22930        0.212800             0.080250   \n",
       "15           0.11390           0.15950        0.163900             0.073640   \n",
       "16           0.09867           0.07200        0.073950             0.052590   \n",
       "17           0.11700           0.20220        0.172200             0.102800   \n",
       "18           0.09831           0.10270        0.147900             0.094980   \n",
       "19           0.09779           0.08129        0.066640             0.047810   \n",
       "20           0.10750           0.12700        0.045680             0.031100   \n",
       "21           0.10240           0.06492        0.029560             0.020760   \n",
       "22           0.10730           0.21350        0.207700             0.097560   \n",
       "23           0.09428           0.10220        0.109700             0.086320   \n",
       "24           0.11210           0.14570        0.152500             0.091700   \n",
       "25           0.11860           0.22760        0.222900             0.140100   \n",
       "26           0.10540           0.18680        0.142500             0.087830   \n",
       "27           0.09440           0.10660        0.149000             0.077310   \n",
       "28           0.10820           0.16970        0.168300             0.087510   \n",
       "29           0.09847           0.11570        0.098750             0.079530   \n",
       "..               ...               ...             ...                  ...   \n",
       "539          0.08668           0.11990        0.092520             0.013640   \n",
       "540          0.09984           0.11200        0.067370             0.025940   \n",
       "541          0.08837           0.12300        0.100900             0.038900   \n",
       "542          0.08275           0.07214        0.041050             0.030270   \n",
       "543          0.08671           0.06877        0.029870             0.032750   \n",
       "544          0.09578           0.10180        0.036880             0.023690   \n",
       "545          0.09246           0.06747        0.029740             0.024430   \n",
       "546          0.09434           0.04994        0.010120             0.005495   \n",
       "547          0.08877           0.08066        0.043580             0.024380   \n",
       "548          0.08491           0.05030        0.023370             0.009615   \n",
       "549          0.08192           0.06602        0.015480             0.008160   \n",
       "550          0.07431           0.04227        0.000000             0.000000   \n",
       "551          0.09566           0.08194        0.048240             0.022570   \n",
       "552          0.08276           0.04234        0.019970             0.014990   \n",
       "553          0.09240           0.05605        0.039960             0.012820   \n",
       "554          0.08123           0.05824        0.061950             0.023430   \n",
       "555          0.09030           0.07658        0.059990             0.027380   \n",
       "556          0.10030           0.07504        0.005025             0.011160   \n",
       "557          0.08123           0.04971        0.000000             0.000000   \n",
       "558          0.08473           0.13300        0.102900             0.037360   \n",
       "559          0.09261           0.10210        0.111200             0.041050   \n",
       "560          0.09929           0.11260        0.044620             0.043040   \n",
       "561          0.07449           0.03558        0.000000             0.000000   \n",
       "562          0.10480           0.20870        0.255000             0.094290   \n",
       "563          0.10990           0.22360        0.317400             0.147400   \n",
       "564          0.11100           0.11590        0.243900             0.138900   \n",
       "565          0.09780           0.10340        0.144000             0.097910   \n",
       "566          0.08455           0.10230        0.092510             0.053020   \n",
       "567          0.11780           0.27700        0.351400             0.152000   \n",
       "568          0.05263           0.04362        0.000000             0.000000   \n",
       "\n",
       "     ...  radius_worst  texture_worst  perimeter_worst  area_worst  \\\n",
       "0    ...        25.380          17.33           184.60      2019.0   \n",
       "1    ...        24.990          23.41           158.80      1956.0   \n",
       "2    ...        23.570          25.53           152.50      1709.0   \n",
       "3    ...        14.910          26.50            98.87       567.7   \n",
       "4    ...        22.540          16.67           152.20      1575.0   \n",
       "5    ...        15.470          23.75           103.40       741.6   \n",
       "6    ...        22.880          27.66           153.20      1606.0   \n",
       "7    ...        17.060          28.14           110.60       897.0   \n",
       "8    ...        15.490          30.73           106.20       739.3   \n",
       "9    ...        15.090          40.68            97.65       711.4   \n",
       "10   ...        19.190          33.88           123.80      1150.0   \n",
       "11   ...        20.420          27.28           136.50      1299.0   \n",
       "12   ...        20.960          29.94           151.70      1332.0   \n",
       "13   ...        16.840          27.66           112.00       876.5   \n",
       "14   ...        15.030          32.01           108.80       697.7   \n",
       "15   ...        17.460          37.13           124.10       943.2   \n",
       "16   ...        19.070          30.88           123.40      1138.0   \n",
       "17   ...        20.960          31.48           136.80      1315.0   \n",
       "18   ...        27.320          30.88           186.80      2398.0   \n",
       "19   ...        15.110          19.26            99.70       711.2   \n",
       "20   ...        14.500          20.49            96.09       630.5   \n",
       "21   ...        10.230          15.66            65.13       314.9   \n",
       "22   ...        18.070          19.08           125.10       980.9   \n",
       "23   ...        29.170          35.59           188.00      2615.0   \n",
       "24   ...        26.460          31.56           177.00      2215.0   \n",
       "25   ...        22.250          21.40           152.40      1461.0   \n",
       "26   ...        17.620          33.21           122.40       896.9   \n",
       "27   ...        21.310          27.26           139.90      1403.0   \n",
       "28   ...        20.270          36.71           149.30      1269.0   \n",
       "29   ...        20.010          19.52           134.90      1227.0   \n",
       "..   ...           ...            ...              ...         ...   \n",
       "539  ...         8.678          31.89            54.49       223.6   \n",
       "540  ...        12.260          19.68            78.78       457.8   \n",
       "541  ...        16.220          31.73           113.50       808.9   \n",
       "542  ...        16.510          32.29           107.40       826.4   \n",
       "543  ...        14.370          37.17            92.48       629.6   \n",
       "544  ...        15.050          24.75            99.17       688.6   \n",
       "545  ...        15.350          29.09            97.58       729.8   \n",
       "546  ...        11.250          21.77            71.12       384.9   \n",
       "547  ...        10.830          22.04            71.08       357.4   \n",
       "548  ...        10.930          25.59            69.10       364.2   \n",
       "549  ...        13.030          31.45            83.90       505.6   \n",
       "550  ...        11.660          24.77            74.08       412.3   \n",
       "551  ...        12.020          28.26            77.80       436.6   \n",
       "552  ...        13.870          36.00            88.10       594.7   \n",
       "553  ...         9.845          25.05            62.86       295.8   \n",
       "554  ...        13.890          35.74            88.84       595.7   \n",
       "555  ...        10.840          34.91            69.57       357.6   \n",
       "556  ...        10.650          22.88            67.88       347.3   \n",
       "557  ...        10.490          34.24            66.50       330.6   \n",
       "558  ...        15.480          27.27           105.90       733.5   \n",
       "559  ...        12.480          37.16            82.28       474.2   \n",
       "560  ...        15.300          33.17           100.20       706.7   \n",
       "561  ...        11.920          38.30            75.19       439.6   \n",
       "562  ...        17.520          42.79           128.70       915.0   \n",
       "563  ...        24.290          29.41           179.10      1819.0   \n",
       "564  ...        25.450          26.40           166.10      2027.0   \n",
       "565  ...        23.690          38.25           155.00      1731.0   \n",
       "566  ...        18.980          34.12           126.70      1124.0   \n",
       "567  ...        25.740          39.42           184.60      1821.0   \n",
       "568  ...         9.456          30.37            59.16       268.6   \n",
       "\n",
       "     smoothness_worst  compactness_worst  concavity_worst  \\\n",
       "0             0.16220            0.66560          0.71190   \n",
       "1             0.12380            0.18660          0.24160   \n",
       "2             0.14440            0.42450          0.45040   \n",
       "3             0.20980            0.86630          0.68690   \n",
       "4             0.13740            0.20500          0.40000   \n",
       "5             0.17910            0.52490          0.53550   \n",
       "6             0.14420            0.25760          0.37840   \n",
       "7             0.16540            0.36820          0.26780   \n",
       "8             0.17030            0.54010          0.53900   \n",
       "9             0.18530            1.05800          1.10500   \n",
       "10            0.11810            0.15510          0.14590   \n",
       "11            0.13960            0.56090          0.39650   \n",
       "12            0.10370            0.39030          0.36390   \n",
       "13            0.11310            0.19240          0.23220   \n",
       "14            0.16510            0.77250          0.69430   \n",
       "15            0.16780            0.65770          0.70260   \n",
       "16            0.14640            0.18710          0.29140   \n",
       "17            0.17890            0.42330          0.47840   \n",
       "18            0.15120            0.31500          0.53720   \n",
       "19            0.14400            0.17730          0.23900   \n",
       "20            0.13120            0.27760          0.18900   \n",
       "21            0.13240            0.11480          0.08867   \n",
       "22            0.13900            0.59540          0.63050   \n",
       "23            0.14010            0.26000          0.31550   \n",
       "24            0.18050            0.35780          0.46950   \n",
       "25            0.15450            0.39490          0.38530   \n",
       "26            0.15250            0.66430          0.55390   \n",
       "27            0.13380            0.21170          0.34460   \n",
       "28            0.16410            0.61100          0.63350   \n",
       "29            0.12550            0.28120          0.24890   \n",
       "..                ...                ...              ...   \n",
       "539           0.15960            0.30640          0.33930   \n",
       "540           0.13450            0.21180          0.17970   \n",
       "541           0.13400            0.42020          0.40400   \n",
       "542           0.10600            0.13760          0.16110   \n",
       "543           0.10720            0.13810          0.10620   \n",
       "544           0.12640            0.20370          0.13770   \n",
       "545           0.12160            0.15170          0.10490   \n",
       "546           0.12850            0.08842          0.04384   \n",
       "547           0.14610            0.22460          0.17830   \n",
       "548           0.11990            0.09546          0.09350   \n",
       "549           0.12040            0.16330          0.06194   \n",
       "550           0.10010            0.07348          0.00000   \n",
       "551           0.10870            0.17820          0.15640   \n",
       "552           0.12340            0.10640          0.08653   \n",
       "553           0.11030            0.08298          0.07993   \n",
       "554           0.12270            0.16200          0.24390   \n",
       "555           0.13840            0.17100          0.20000   \n",
       "556           0.12650            0.12000          0.01005   \n",
       "557           0.10730            0.07158          0.00000   \n",
       "558           0.10260            0.31710          0.36620   \n",
       "559           0.12980            0.25170          0.36300   \n",
       "560           0.12410            0.22640          0.13260   \n",
       "561           0.09267            0.05494          0.00000   \n",
       "562           0.14170            0.79170          1.17000   \n",
       "563           0.14070            0.41860          0.65990   \n",
       "564           0.14100            0.21130          0.41070   \n",
       "565           0.11660            0.19220          0.32150   \n",
       "566           0.11390            0.30940          0.34030   \n",
       "567           0.16500            0.86810          0.93870   \n",
       "568           0.08996            0.06444          0.00000   \n",
       "\n",
       "     concave points_worst  symmetry_worst  fractal_dimension_worst  \n",
       "0                 0.26540          0.4601                  0.11890  \n",
       "1                 0.18600          0.2750                  0.08902  \n",
       "2                 0.24300          0.3613                  0.08758  \n",
       "3                 0.25750          0.6638                  0.17300  \n",
       "4                 0.16250          0.2364                  0.07678  \n",
       "5                 0.17410          0.3985                  0.12440  \n",
       "6                 0.19320          0.3063                  0.08368  \n",
       "7                 0.15560          0.3196                  0.11510  \n",
       "8                 0.20600          0.4378                  0.10720  \n",
       "9                 0.22100          0.4366                  0.20750  \n",
       "10                0.09975          0.2948                  0.08452  \n",
       "11                0.18100          0.3792                  0.10480  \n",
       "12                0.17670          0.3176                  0.10230  \n",
       "13                0.11190          0.2809                  0.06287  \n",
       "14                0.22080          0.3596                  0.14310  \n",
       "15                0.17120          0.4218                  0.13410  \n",
       "16                0.16090          0.3029                  0.08216  \n",
       "17                0.20730          0.3706                  0.11420  \n",
       "18                0.23880          0.2768                  0.07615  \n",
       "19                0.12880          0.2977                  0.07259  \n",
       "20                0.07283          0.3184                  0.08183  \n",
       "21                0.06227          0.2450                  0.07773  \n",
       "22                0.23930          0.4667                  0.09946  \n",
       "23                0.20090          0.2822                  0.07526  \n",
       "24                0.20950          0.3613                  0.09564  \n",
       "25                0.25500          0.4066                  0.10590  \n",
       "26                0.27010          0.4264                  0.12750  \n",
       "27                0.14900          0.2341                  0.07421  \n",
       "28                0.20240          0.4027                  0.09876  \n",
       "29                0.14560          0.2756                  0.07919  \n",
       "..                    ...             ...                      ...  \n",
       "539               0.05000          0.2790                  0.10660  \n",
       "540               0.06918          0.2329                  0.08134  \n",
       "541               0.12050          0.3187                  0.10230  \n",
       "542               0.10950          0.2722                  0.06956  \n",
       "543               0.07958          0.2473                  0.06443  \n",
       "544               0.06845          0.2249                  0.08492  \n",
       "545               0.07174          0.2642                  0.06953  \n",
       "546               0.02381          0.2681                  0.07399  \n",
       "547               0.08333          0.2691                  0.09479  \n",
       "548               0.03846          0.2552                  0.07920  \n",
       "549               0.03264          0.3059                  0.07626  \n",
       "550               0.00000          0.2458                  0.06592  \n",
       "551               0.06413          0.3169                  0.08032  \n",
       "552               0.06498          0.2407                  0.06484  \n",
       "553               0.02564          0.2435                  0.07393  \n",
       "554               0.06493          0.2372                  0.07242  \n",
       "555               0.09127          0.2226                  0.08283  \n",
       "556               0.02232          0.2262                  0.06742  \n",
       "557               0.00000          0.2475                  0.06969  \n",
       "558               0.11050          0.2258                  0.08004  \n",
       "559               0.09653          0.2112                  0.08732  \n",
       "560               0.10480          0.2250                  0.08321  \n",
       "561               0.00000          0.1566                  0.05905  \n",
       "562               0.23560          0.4089                  0.14090  \n",
       "563               0.25420          0.2929                  0.09873  \n",
       "564               0.22160          0.2060                  0.07115  \n",
       "565               0.16280          0.2572                  0.06637  \n",
       "566               0.14180          0.2218                  0.07820  \n",
       "567               0.26500          0.4087                  0.12400  \n",
       "568               0.00000          0.2871                  0.07039  \n",
       "\n",
       "[569 rows x 32 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# melihat isi dari raw_data\n",
    "raw_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mengambil indeks kolom ke 1 sampai indeks paling akhir\n",
    "kolom = raw_data.columns[1:]\n",
    "\n",
    "# mengambil raw_data dari kolom yang sudah didefinisikan\n",
    "raw_data = raw_data[kolom].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "raw_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Inspeksi Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# cek summary\n",
    "raw_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Cek Nilai yang hilang\n",
    "raw_data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# buat variabel baru dengan diagnosis difokuskan pada apakah\n",
    "# tumor termasuk ganas atau tidak ('malignant' atau 'not malignant')\n",
    "raw_data['diagnosis'] = pd.get_dummies(raw_data['diagnosis'])['M']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cek class imbalance\n",
    "raw_data['diagnosis'].value_counts().plot.bar();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Train-Test Splitting**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# train-test split\n",
    "training_data = raw_data.groupby('diagnosis', group_keys=False).apply(lambda x: x.sample(frac = .8, random_state=1000)).copy()\n",
    "\n",
    "training_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_data = raw_data.drop(training_data.index)\n",
    "\n",
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# buat train set\n",
    "X_train = training_data.iloc[:,1:].values\n",
    "y_train = training_data['diagnosis'].values\n",
    "\n",
    "# buat validation/test set\n",
    "X_test = test_data.iloc[:,1:].values\n",
    "y_test = test_data['diagnosis'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayes Classifier\n",
    "\n",
    "Bayes Classifier (disebut juga *Naive Bayes Classifier*) adalah salah satu model machine learning yang mana menginsyaratkan tidak adanya keterkaitan antar fitur."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dasar Teori\n",
    "\n",
    "Classifier Bayes dirumuskan berdasarkan Teorema Bayes berikut:\n",
    "\n",
    "Misalkan terdapat dua kejadian $A$ dan $B$. Kita dapat mengkaitkan masing-masing probabilitas dari dua kejadian ini, $P(A)$ dan $P(B)$, dengan probabilitas kondisional $P(A|B)$ dan $P(B|A)$ berdasarkan aturan berikut:\n",
    "\n",
    "$$\n",
    "P(A \\cap B) = P(A|B)P(B)\n",
    "$$\n",
    "\n",
    "atau\n",
    "\n",
    "$$\n",
    "P(B \\cap A) = P(B|A)P(A)\n",
    "$$\n",
    "\n",
    "Karena\n",
    "\n",
    "$$P(A \\cap B) = P(B \\cap A)$$\n",
    "\n",
    "maka persamaan diatas dapat ditulis kembali sebagai:\n",
    "\n",
    "$$\n",
    "P(A|B) = \\frac{P(B|A)P(A)}{P(B)}\n",
    "$$\n",
    "\n",
    "**Mengapa Menggunakan Naive Bayes**\n",
    "\n",
    "- Cepat\n",
    "- Hanya membutuhkan sedikit parameter\n",
    "- Out-of-core learning\n",
    "\n",
    "**Mengapa Tidak Menggunakan Naive Bayes**\n",
    "\n",
    "- Base model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes pada Scikit-Learn\n",
    "\n",
    "Terdapat 3 implementasi Naive Bayes pada Scikit-Learn, diantaranya:\n",
    "\n",
    "- Bernoulli Naive Bayes (```BernoulliNB```)\n",
    "- Multinomial Naive Bayes (```MultinomialNB```)\n",
    "- Gaussian Naive Bayes (```GaussianNB```)\n",
    "- Complement Naive Bayes (```ComplementNB```)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bernoulli Naive Bayes\n",
    "\n",
    "Bernoulli Naive Bayes digunakan jika sebaran data mengikuti distribusi Bernoulli.\n",
    "\n",
    "**Kapan Menggunakan Bernoulli Naive Bayes**\n",
    "\n",
    "- Ketika tiap fitur dalam matriks bernilai biner 0-1. Misalnya bernilai 0 jika kata tersebut tidak ada di dalam teks, dan 1 jika kata tersebut ada di dalam teks.\n",
    "- Cocok untuk klasifikasi pesan singkat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multinomial Naive Bayes\n",
    "\n",
    "Multinomial Naive Bayes digunakan untuk data yang sifatnya diskrit.\n",
    "\n",
    "**Kapan Menggunakan Multinomial Naive Bayes**\n",
    "\n",
    "- Ketika tiap fitur dalam matriks memiliki nilai diskrit, misalnya dari hasil counting.\n",
    "- Cocok untuk klasifikasi teks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian Naive Bayes\n",
    "\n",
    "Gaussian Naive Bayes digunakan untuk data dengan fitur numerik.\n",
    "\n",
    "**Kapan Menggunakan Gaussian Naive Bayes**\n",
    "\n",
    "- Ketika tiap fitur dalam matriks memiliki nilai numerik"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Syntax GaussianNB**\n",
    "\n",
    "```python\n",
    "GaussianNB(priors=None, var_smoothing=1e-09)\n",
    "```\n",
    "\n",
    "Keterangan:\n",
    "\n",
    "- ```priors```: Probabilitas prior dari kelas.\n",
    "- ```var_smoothing```: Proporsi variansi terbesar dari seluruh variabel yang digunakan untuk modeling \n",
    "\n",
    "Keterangan lebih lanjut: https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.GaussianNB.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Penerapan Model Gaussian Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load modul GaussianNB\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# inisiasi model\n",
    "model_nb_gaussian = GaussianNB()\n",
    "\n",
    "# fitting model\n",
    "model_nb_gaussian.fit(X_train, y_train)\n",
    "\n",
    "# buat hasil prediksi\n",
    "hasil_prediksi = model_nb_gaussian.predict(X_test)\n",
    "\n",
    "# lihat hasil prediksi\n",
    "hasil_prediksi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model Evaluation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Cek Akurasi**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_test, hasil_prediksi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Catatan** \n",
    "\n",
    "*Accuracy (Akurasi)*\n",
    "\n",
    "Akurasi adalah salah satu metrik yang biasa digunakan dalam menghitung seberapa baik model yang dibuat dalam memprediksi.\n",
    "\n",
    "$$Accuracy = \\frac{True Positive + True Negative}{True Positive + False Positive + True Negative + False Negative}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Confusion Matrix**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "confusion_matrix(y_test, hasil_prediksi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Catatan**\n",
    "\n",
    "*Confusion Matrix*\n",
    "\n",
    "Confusion Matrix digunakan untuk melakukan tabulasi silang terhadap hasil antara nilai sebenarnya dengan nilai prediksi.\n",
    "\n",
    "\n",
    "```python\n",
    "array([[66,  5],\n",
    "       [ 6, 36]])\n",
    "```\n",
    "\n",
    "Maka:\n",
    "\n",
    "- True Negative: 66\n",
    "- False Positive: 5\n",
    "- False Negative: 6\n",
    "- True Positive: 36"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Classification Report**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(classification_report(y_test, hasil_prediksi, target_names=['0','1'], output_dict=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Catatan**\n",
    "\n",
    "![Precision Recall](./images/meme-1.jpg)\n",
    "\n",
    "*precision*\n",
    "\n",
    "precision adalah\n",
    "\n",
    "$$\\frac{True Positive}{True Positive + False Positive}$$\n",
    "\n",
    "*recall* (atau Sensitivity)\n",
    "\n",
    "recall adalah\n",
    "\n",
    "$$\\frac{True Positive}{True Positive + False Negative}$$\n",
    "\n",
    "*f1-score*\n",
    "\n",
    "f1-score adalah \n",
    "\n",
    "$$2\\times(\\frac{precision \\times recall}{precision+recall})$$\n",
    "\n",
    "Makin besar nilainya makin baik.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = [0, 0, 0, 1, 1, 1, 1, 1]\n",
    "y_pred = [0, 1, 0, 1, 0, 1, 0, 1]\n",
    "tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "tn, fp, fn, tp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model Inspection**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame({\n",
    "    \"Kelas\": [0,1],\n",
    "    \"Probabilitas\": model_nb_gaussian.class_prior_\n",
    "}).plot.bar('Kelas','Probabilitas');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame({\n",
    "    \"Fitur\": training_data.iloc[:,1:].columns,\n",
    "    \"Rerata fitur terhadap kelas Malignant\": model_nb_gaussian.theta_[1]\n",
    "}).sort_values(by='Rerata fitur terhadap kelas Malignant', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Receiver Operating Characteristic (ROC) & Area Under Curve (AUC)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "visualizer = ROCAUC(model_nb_gaussian, classes=['Not Malignant', 'Malignant'])\n",
    "visualizer.fit(X_train, y_train)\n",
    "visualizer.score(X_test, y_test)\n",
    "visualizer.finalize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Catatan Terkait ROC-AUC\n",
    "\n",
    "ROC adalah suatu plot yang terdiri dari nilai True Positive Rate (Sensitivity) dan False Positive Rate, dimana\n",
    "\n",
    "$$False Positive Rate = \\frac{False Positive}{False Positive + False Negative}$$\n",
    "\n",
    "Sedangkan AUC adalah luas area dibawah kurva ROC. AUC dapat dipakai untuk mengukur seberapa baik performa dari model. Semakin mendekati 1 semakin baik.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Precision-Recall Curve**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "viz = PrecisionRecallCurve(model_nb_gaussian)\n",
    "viz.fit(X_train, y_train)\n",
    "viz.score(X_test, y_test)\n",
    "viz.finalize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Catatan**\n",
    "\n",
    "*Precision-Recall Curve*\n",
    "\n",
    "*Precision-Recall Curve* adalah kurva yang dibentuk dari nilai precision dan recall. Biasanya dipakai untuk menentukan seberapa baik performa dari model terutama jika terjadinya imbalance class.\n",
    "\n",
    "*Average Precision* adalah salah satu cara untuk untuk menghitung seberapa baik performa dari model jika kita menggunakan Precision-Recall Curve. Average Precision dirumuskan sebagai berikut:\n",
    "\n",
    "$$Average Precision = \\Sigma_{n}(Recall_{n} - Recall_{n-1}) \\times Precision_{n}$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Complement Naive Bayes\n",
    "\n",
    "Complement Naive Bayes mirip dengan multinomial naive Bayes, hanya saja digunakan untuk kasus dimana data memiliki kelas target yang tidak imbang (*imbalance*).\n",
    "\n",
    "**Kapan Menggunakan Complement Naive Bayes**\n",
    "\n",
    "- Ketika kelas target tidak seimbang"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Syntax ComplementNB**\n",
    "\n",
    "```python\n",
    "ComplementNB(alpha=1.0, fit_prior=True, class_prior=None, norm=False)\n",
    "```\n",
    "\n",
    "Keterangan: \n",
    "\n",
    "- ```alpha```: Penggunaan smoothing parameter. Berfungsi untuk mencegah nilai probabilitas bernilai 0 karena variabel yang dipakai model berbeda dengan data aslinya.\n",
    "- ```fit_prior```: Hanya digunakan jika terdapat 1 kelas saja pada kelas target.\n",
    "- ```class_prior```: Probabilitas prior untuk tiap kelas target.\n",
    "\n",
    "Keterangan lebih lanjut: https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.ComplementNB.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Penerapan Model Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load modul GaussianNB\n",
    "from sklearn.naive_bayes import ComplementNB\n",
    "\n",
    "# inisiasi model\n",
    "model_nb_complement = ComplementNB(fit_prior=False)\n",
    "\n",
    "# fitting model\n",
    "model_nb_complement.fit(X_train, y_train)\n",
    "\n",
    "# buat hasil prediksi\n",
    "hasil_prediksi = model_nb_complement.predict(X_test)\n",
    "\n",
    "# lihat hasil prediksi\n",
    "hasil_prediksi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Evaluasi Hasil Prediksi**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Cek Akurasi**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_test, hasil_prediksi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Confusion Matrix**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "confusion_matrix(y_test, hasil_prediksi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Classification Report**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(classification_report(y_test, hasil_prediksi, target_names=['0','1'], output_dict=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model Inspection**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame({\n",
    "    \"Variabel\": training_data.iloc[:,1:].columns,\n",
    "    \"Weight\": model_nb_complement.coef_[0]\n",
    "}).sort_values(by='Weight', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame({\n",
    "    \"Variabel\":training_data.iloc[:,1:].columns,\n",
    "    \"Empirical Weight\": model_nb_complement.feature_log_prob_[1]\n",
    "}).sort_values(by='Empirical Weight', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Receiver Operating Characteristic (ROC) & Area Under Curve (AUC)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "visualizer = ROCAUC(model_nb_complement, classes=['Not Malignant', 'Malignant'])\n",
    "visualizer.fit(X_train, y_train)\n",
    "visualizer.score(X_test, y_test)\n",
    "visualizer.finalize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Precision-Recall Curve**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viz = PrecisionRecallCurve(model_nb_complement)\n",
    "viz.fit(X_train, y_train)\n",
    "viz.score(X_test, y_test)\n",
    "viz.finalize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Logistic Regression](./images/logistic_regression.png)\n",
    "\n",
    "Sumber Gambar: https://medium.com/@ODSC/logistic-regression-with-python-ede39f8573c7\n",
    "\n",
    "### Dasar Teori\n",
    "\n",
    "Logistic Regression adalah salah satu model parametrik yang menggunakan fungsi logistik untuk melakukan fitting pada data:\n",
    "\n",
    "$$f(\\bar{x},\\bar{w}) = \\frac{1}{1+e^{-\\bar{x}\\bar{w}}}$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Kapan Menggunakan Logistic Regression**\n",
    "\n",
    "- Jika data yang dipakai untuk pemodelan tidak terlalu besar\n",
    "- Sebagai base model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Syntax LogisticRegression**\n",
    "\n",
    "```python\n",
    "LogisticRegression(penalty=l2, dual=False, tol=0.0001, C=1.0, fit_intercept=True, intercept_scaling=1, class_weight=None, random_state=None, solver=warn, max_iter=100, multi_class=warn, verbose=0, warm_start=False, n_jobs=None, l1_ratio=None)\n",
    "```\n",
    "\n",
    "Keterangan:\n",
    "\n",
    "- ```penalty```: Pemilihan fungsi norm yang digunakan untuk *penalization*. Pilihannya adalah ```l1```, ```l2```, ```elasticnet``` dan ```none```\n",
    "- ```dual```: Formulasi \"dual\" atau \"primal\".\n",
    "- ```tol```: Nilai toleransi error\n",
    "- ```C```: Berfungsi untuk *regularization* untuk menghindari kasus *overfitting*\n",
    "- ```fit_intercept```: Apakah menggunakan *intercept* atau tidak.\n",
    "- ```class_weight```: Memberikan pembobotan pada kelas target.\n",
    "- ```random_state```: Berfungsi untuk melakukan seeding pada RNG.\n",
    "- ```solver```: Algoritma yang digunakan untuk fitting model.\n",
    "    - Gunakan liblinear untuk dataset kecil, gunakan sag dan saga untuk data ukuran besar.\n",
    "    - Untuk kasus multiclass, gunakan newton-cg, sag, saga dan lbfgs untuk multinomial.\n",
    "    - newton-cg, lbfgs, sag dan saga dapat melakukan regularisasi L2 atau tanpa penalti\n",
    "    - liblinear dan saga dapat melakukan regularisasi menggunakan L1\n",
    "    - saga dapat menggunakan regularisasi menggunakan elasticnet\n",
    "    - liblinear harus menggunakan penalti\n",
    "- ```max_iter```: Iterasi maksimal\n",
    "- ```multi_class```: Apakah kasusnya binary atau multiclass.\n",
    "    - Gunakan ovr untuk kasus binary\n",
    "    - Gunakan multinomial untuk kasus multiclass\n",
    "    - Gunakan 'auto' untuk memilih secara otomatis tergantung dari kelas targetnya\n",
    "- ```n_jobs```: Jumlah core CPU yang digunakan untuk pemodelan\n",
    "\n",
    "Sisanya dapat dibaca di: https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Penerapan Model Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model_logistic_reg = LogisticRegression(random_state=1000, solver='liblinear', multi_class='ovr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# fitting model\n",
    "model_logistic_reg.fit(X_train, y_train)\n",
    "\n",
    "# buat hasil prediksi\n",
    "hasil_prediksi = model_logistic_reg.predict(X_test)\n",
    "\n",
    "# lihat hasil prediksi\n",
    "hasil_prediksi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Evaluasi Model**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Akurasi**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_test, hasil_prediksi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Confusion Matrix**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y_test, hasil_prediksi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Classification Report**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(classification_report(y_test, hasil_prediksi, output_dict=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model Inspection**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Coefficients Weight**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nama_feature = training_data.iloc[:,1:].columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eli5.explain_weights(model_logistic_reg, feature_names=nama_feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Receiver Operating Characteristic (ROC) & Area Under Curve (AUC)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualizer = ROCAUC(model_logistic_reg, classes=['Not Malignant', 'Malignant'])\n",
    "visualizer.fit(X_train, y_train)\n",
    "visualizer.score(X_test, y_test)\n",
    "visualizer.finalize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Precision-Recall Curves**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viz = PrecisionRecallCurve(model_logistic_reg)\n",
    "viz.fit(X_train, y_train)\n",
    "viz.score(X_test, y_test)\n",
    "viz.finalize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Nearest Neighbors\n",
    "\n",
    "![KNN](./images/knn_.png)\n",
    "\n",
    "Sumber Gambar: https://www.kdnuggets.com/2019/07/classifying-heart-disease-using-k-nearest-neighbors.html\n",
    "\n",
    "### Dasar Teori\n",
    "\n",
    "K-Nearest Neighbors (KNN) adalah salah satu model machine learning non-parametrik dimana model menggunakan posisi dari tiap titik data pada saat training untuk mengklasifikasikan data yang baru.\n",
    "\n",
    "Karena posisi titik sangat diperhitungkan, maka KNN bergantung kepada fungsi jarak yang digunakan dalam pemodelan, diantaranya:\n",
    "\n",
    "**Jarak Manhatan (*Manhatan Distance*)**\n",
    "\n",
    "$$d(x,y) = \\Sigma_{i=1}^{k} |x_{i} - y_{i}|$$\n",
    "\n",
    "**Jarak Euclidean (*Euclidean Distance*)**\n",
    "\n",
    "$$d(x,y) = \\sqrt{\\Sigma_{i=1}^{k} (x_{i} - y_{i})^{2}}$$\n",
    "\n",
    "**Jarak Minkowski (*Minkowski Distance*)**\n",
    "\n",
    "$$d(x,y) = (\\Sigma_{i=1}^{k} (x_{i} - y_{i})^{p})^{p}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Kapan Menggunakan K-Nearest Neighbors**\n",
    "\n",
    "- Base model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Syntax KNeighborsClassifier**\n",
    "\n",
    "```python\n",
    "KNeighborsClassifier(n_neighbors=5, weights=uniform, algorithm=auto, p=2, metric=minkowski, n_jobs=None)\n",
    "```\n",
    "\n",
    "Keterangan: \n",
    "\n",
    "- ```n_neigbors```: Jumlah titik yang digunakan untuk menentukan kelas dari data yang baru.\n",
    "- ```weights```: Pembobotan yang dipakai untuk melakukan prediksi. Terdapat 2 pilihan, yaitu:\n",
    "    - ```uniform```: Setiap titik diperlakukan sama\n",
    "    - ```distance```: Setiap titik diberi bobot berdasarkan inverse jarak.\n",
    "- ```algorithm```: Algoritma yang dipakai untuk menghitung nilai ketetanggaan antar titik. Terdapat 4 pilihan:\n",
    "    - ```balll_tree```\n",
    "    - ```kd_tree```\n",
    "    - ```brute```\n",
    "    - ```auto```\n",
    "- ```p```: Derajat atau pangkat yang digunakan untuk menghitung jarak antar titik berdasarkan rumus jarak Minkowski. \n",
    "    - Jika ```p=1```, maka jarak yang digunakan jarak Manhatan\n",
    "    - Jika ```p=2```, maka jarak yang digunakan jarak Euclidean\n",
    "- ```metric```: Fungsi jarak yang dipakai untuk menghitung jarak antar titik\n",
    "- ```n_jobs```: Berapa banyak CPU yang digunakan untuk membuat model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Penerapan Model K-Nearest Neighbors**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "model_knn = KNeighborsClassifier(n_neighbors=3, algorithm='auto')\n",
    "\n",
    "model_knn.fit(X_train, y_train)\n",
    "\n",
    "hasil_prediksi = model_knn.predict(X_test)\n",
    "\n",
    "hasil_prediksi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Evaluasi**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_test, hasil_prediksi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y_test, hasil_prediksi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(\n",
    "classification_report(y_test, hasil_prediksi, output_dict=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model Inspection**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Receiver Operating Characteristic (ROC) & Area Under Curve (AUC)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualizer = ROCAUC(model_knn, classes=['Not Malignant', 'Malignant'])\n",
    "visualizer.fit(X_train, y_train)\n",
    "visualizer.score(X_test, y_test)\n",
    "visualizer.finalize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Precission-Recall Curve**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viz = PrecisionRecallCurve(model_knn)\n",
    "viz.fit(X_train, y_train)\n",
    "viz.score(X_test, y_test)\n",
    "viz.finalize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree\n",
    "\n",
    "![Decision Tree](./images/decision_tree.png)\n",
    "\n",
    "Sumber Gambar: https://www.displayr.com/what-is-a-decision-tree/\n",
    "\n",
    "### Dasar Teori\n",
    "\n",
    "Decision Tree adalah salah satu model machine learning non parametrik yang didasarkan pada pembentukan pohon keputusan. Model ini dibangun dengan cara menentukan root node, lalu membentuk cabang-cabang keputusan yang dibuat berdasarkan ukuran tertentu yang disebut sebagai *split criteria* atau *impurity measures*. Hasil yang diperoleh dari decision tree bisa berupa aturan-aturan yang dapat diinterpretasikan ke dalam bahasa manusia sehingga model decision tree lebih mudah dipahami oleh orang awam sekalipun.\n",
    "\n",
    "**Beberapa *Split Criteria/Impurity Measures***\n",
    "\n",
    "![Impurity Measures](./images/impurity.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Kapan Menggunakan Decision Tree**\n",
    "\n",
    "- Ketika membutuhkan model yang memiliki performa lebih baik dibanding base model dan mudah diinterpretasikan\n",
    "- Ketika masalah yang ingin diselesaikan adalah masalah bisnis dimana membutuhkan panduan dalam membuat keputusan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Syntax DecisionTreeClassifier**\n",
    "\n",
    "```python\n",
    "DecisionTreeClassifier(criterion=gini, splitter=best, max_depth=None, min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features=None, random_state=None, max_leaf_nodes=None, min_impurity_decrease=0.0, min_impurity_split=None, class_weight=None, presort=False)\n",
    "```\n",
    "\n",
    "Keterangan:\n",
    "\n",
    "- ```criterion```: ukuran yang dipakai untuk melakukan split pada node, terdapat dua pilihan yaitu 'gini' untuk penggunaan gini index dan 'entropy' untuk penggunaan information gain.\n",
    "- ```splitter```: strategi yang digunakan untuk split pada tiap node, terdapat dua pilihan yaitu 'best' dan 'random'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "model_decision_tree = DecisionTreeClassifier(random_state=1000)\n",
    "\n",
    "model_decision_tree.fit(X_train, y_train)\n",
    "\n",
    "hasil_prediksi = model_decision_tree.predict(X_test)\n",
    "\n",
    "hasil_prediksi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model Evaluation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_test, hasil_prediksi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y_test, hasil_prediksi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(\n",
    "classification_report(y_test, hasil_prediksi, output_dict=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model Inspection**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Feature Importance & Rules**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "eli5.sklearn.explain_decision_tree(model_decision_tree, feature_names=training_data.iloc[:,1:].columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tree Visualization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import graphviz\n",
    "dot_data = tree.export_graphviz(model_decision_tree, out_file=None, filled=True, rounded=True, special_characters=True)\n",
    "graph = graphviz.Source(dot_data)\n",
    "graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Receiver Operating Characteristic (ROC) & Area Under Curve (AUC)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualizer = ROCAUC(model_decision_tree, classes=['Not Malignant', 'Malignant'])\n",
    "visualizer.fit(X_train, y_train)\n",
    "visualizer.score(X_test, y_test)\n",
    "visualizer.finalize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Precission-Recall Curve**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viz = PrecisionRecallCurve(model_decision_tree)\n",
    "viz.fit(X_train, y_train)\n",
    "viz.score(X_test, y_test)\n",
    "viz.finalize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AdaBoost\n",
    "\n",
    "![AdaBoost](./images/adaboost.png)\n",
    "\n",
    "Sumber Gambar: https://medium.com/swlh/boosting-and-bagging-explained-with-examples-5353a36eb78d\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Kapan Menggunakan AdaBoost**\n",
    "\n",
    "- Ketika akurasi lebih diutamakan dibanding interpretabilitas.\n",
    "- Mencari tahu mana variabel yang lebih penting dibanding variabel lainnya menggunakan feature importance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Syntax AdaBoostClassifier**\n",
    "\n",
    "```python\n",
    "AdaBoostClassifier(base_estimator=None, n_estimators=50, learning_rate=1.0, algorithm=SAMME.R, random_state=None)\n",
    "```\n",
    "\n",
    "Keterangan:\n",
    "\n",
    "- ```base_estimator```: Estimator yang digunakan untuk membuat model.\n",
    "- ```n_estimators```: Banyak estimator yang dibuat.\n",
    "- ```learning_rate```: Berfungsi untuk memperkecil kontribusi tiap estimator yang dibuat.\n",
    "- ```algorithm```: Algoritma yang digunakan untuk. Terdapat dua pilihan, yaitu 'SAMME' dan 'SAMME.R'\n",
    "- ```random_state```: Berfungsi untuk seeding random number generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "model_adaboost = AdaBoostClassifier(random_state=1000)\n",
    "\n",
    "model_adaboost.fit(X_train, y_train)\n",
    "\n",
    "hasil_prediksi = model_adaboost.predict(X_test)\n",
    "\n",
    "hasil_prediksi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model Evaluation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_test, hasil_prediksi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y_test, hasil_prediksi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(\n",
    "classification_report(y_test, hasil_prediksi, output_dict=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model Inspection**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Feature Importance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eli5.explain_weights(model_adaboost, feature_names=training_data.iloc[:,1:].columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Receiver Operating Characteristic (ROC) & Area Under Curve (AUC)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualizer = ROCAUC(model_adaboost, classes=['Not Malignant', 'Malignant'])\n",
    "visualizer.fit(X_train, y_train)\n",
    "visualizer.score(X_test, y_test)\n",
    "visualizer.finalize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Precision-Recall Curve**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viz = PrecisionRecallCurve(model_adaboost)\n",
    "viz.fit(X_train, y_train)\n",
    "viz.score(X_test, y_test)\n",
    "viz.finalize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest\n",
    "\n",
    "![Random Forest](./images/random_forest.png)\n",
    "\n",
    "Sumber gambar: https://www.machinehack.com/course/machinehack-practise-5-random-forest-regression/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Kapan Menggunakan Random Forest**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Syntax RandomForest**\n",
    "\n",
    "```python\n",
    "RandomForestClassifier(n_estimators=warn, criterion=gini, max_depth=None, min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features=auto, max_leaf_nodes=None, min_impurity_decrease=0.0, min_impurity_split=None, bootstrap=True, oob_score=False, n_jobs=None, random_state=None, verbose=0, warm_start=False, class_weight=None)\n",
    "```\n",
    "\n",
    "Keterangan:\n",
    "\n",
    "- ```n_estimators```: Jumlah pohon yang dibuat.\n",
    "- ```criterion```: Kriteria yang digunakan untuk melakukan split pada node. Terdapat dua pilihan, diantaranya 'gini' untuk penggunaan gini index dan 'entropy' untuk penggunaan information gain.\n",
    "- ```max_depth```: Seberapa banyak node yang akan dibentuk. Semakin besar maka semakin dalam pohon yang dibuat.\n",
    "- ```min_sample_split```: Jumlah sampel minimum yang digunakan node untuk split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "model_randomforest = RandomForestClassifier(n_estimators=100, random_state=1000, max_depth=4)\n",
    "\n",
    "model_randomforest.fit(X_train, y_train)\n",
    "\n",
    "hasil_prediksi = model_randomforest.predict(X_test)\n",
    "\n",
    "hasil_prediksi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model Evaluation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_test, hasil_prediksi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y_test, hasil_prediksi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(\n",
    "classification_report(y_test, hasil_prediksi, output_dict=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model Inspection**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Feature Importance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "eli5.sklearn.explain_rf_feature_importance(model_randomforest, feature_names=training_data.iloc[:,1:].columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Receiver Operating Characteristic (ROC) & Area Under Curve (AUC)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualizer = ROCAUC(model_randomforest, classes=['Not Malignant', 'Malignant'])\n",
    "visualizer.fit(X_train, y_train)\n",
    "visualizer.score(X_test, y_test)\n",
    "visualizer.finalize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Precision-Recall Curve**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viz = PrecisionRecallCurve(model_randomforest)\n",
    "viz.fit(X_train, y_train)\n",
    "viz.score(X_test, y_test)\n",
    "viz.finalize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosting Tree\n",
    "\n",
    "![Gradient Boosting Tree](./images/gradient_boosting_tree.png)\n",
    "\n",
    "Sumber gambar: https://bradleyboehmke.github.io/HOML/gbm.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Kapan Menggunakan Gradient Boosting Tree**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Syntax GradientBoostingClassifier**\n",
    "\n",
    "```python\n",
    "GradientBoostingClassifier(loss=deviance, learning_rate=0.1, n_estimators=100, subsample=1.0, criterion=friedman_mse, min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_depth=3, min_impurity_decrease=0.0, min_impurity_split=None, init=None, random_state=None, max_features=None, verbose=0, max_leaf_nodes=None, warm_start=False, presort=auto, validation_fraction=0.1, n_iter_no_change=None, tol=0.0001)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "model_gradient_boosting = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0, max_depth=1, random_state=1000)\n",
    "\n",
    "model_gradient_boosting.fit(X_train, y_train)\n",
    "\n",
    "hasil_prediksi = model_gradient_boosting.predict(X_test)\n",
    "\n",
    "hasil_prediksi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model Evaluation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_test, hasil_prediksi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y_test, hasil_prediksi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(\n",
    "classification_report(y_test, hasil_prediksi, output_dict=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model Inspection**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eli5.explain_weights(model_gradient_boosting, feature_names=training_data.iloc[:,1:].columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Receiver Operating Characteristic (ROC) & Area Under Curve (AUC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualizer = ROCAUC(model_gradient_boosting, classes=['Not Malignant', 'Malignant'])\n",
    "visualizer.fit(X_train, y_train)\n",
    "visualizer.score(X_test, y_test)\n",
    "visualizer.finalize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Precision-Recall Curve**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viz = PrecisionRecallCurve(model_randomforest)\n",
    "viz.fit(X_train, y_train)\n",
    "viz.score(X_test, y_test)\n",
    "viz.finalize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machine\n",
    "\n",
    "![SVM](./images/svm.png)\n",
    "\n",
    "Sumber gambar: https://www.datacamp.com/community/tutorials/svm-classification-scikit-learn-python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Kapan Menggunakan SVM**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Syntax SVC**\n",
    "\n",
    "```python\n",
    "SVC(C=1.0, kernel=rbf, degree=3, gamma=auto_deprecated, coef0=0.0, shrinking=True, probability=False, tol=0.001, cache_size=200, class_weight=None, verbose=False, max_iter=-1, decision_function_shape=ovr, random_state=None)\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "model_svm = SVC(kernel='linear', gamma = 'scale', random_state=1000, probability=True)\n",
    "\n",
    "model_svm.fit(X_train, y_train)\n",
    "\n",
    "hasil_prediksi = model_svm.predict(X_test)\n",
    "\n",
    "hasil_prediksi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model Evaluation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_test, hasil_prediksi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y_test, hasil_prediksi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(\n",
    "classification_report(y_test, hasil_prediksi, output_dict=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model Inspection**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eli5.explain_weights(model_svm, feature_names=nama_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "visualizer = ROCAUC(model_svm, classes=['Not Malignant', 'Malignant'])\n",
    "visualizer.fit(X_train, y_train)\n",
    "visualizer.score(X_test, y_test)\n",
    "visualizer.finalize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viz = PrecisionRecallCurve(model_randomforest)\n",
    "viz.fit(X_train, y_train)\n",
    "viz.score(X_test, y_test)\n",
    "viz.finalize()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
